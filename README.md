# thought-whitepaper


THOUGHT - The global, decentralized, Data-defined Processing Network

Unlocking the knowledge potential of the world's data with a Universal Turing Machine

1. Abstract 

Mission - Our goal is to unlock the knowledge potential of the world’s data.  The Thought Network will create an insight layer on the internet to manage the world's data based on data- defined processing and artificial intelligence networks. The Thought Network is a solution enabling architecture with a full developer ecosystem. Through it's use of "Smart Data" automata, the Thought Network is a global Universal Turing Machine.

Problem 

The number of devices on the Internet is exponentially increasing and massive amounts of data are trapped in siloed applications and databases. According to the International Data Corporation, 180 Zetabytes (180 trillion gigabytes) will be created annually by 2025. Our data-centric world is challenging: finding insight and value in this volume of incompatible data is demanding, element-level database encryption is cumbersome at best as a data privacy and cybersecurity control; and standardized data ownership mechanisms just don't exist. Once data  leaves a device (commercial or consumer) it's no longer under the owner's control and a group of large monolithic service providers have made a business of consolidating and benefiting from personal data. 

Solution 

The solution is to couple ordinary data with programmatic logic to create Smart Data, - called a "Nuance".  A Nuance can be considered a "digital neuron" that receives and processes inputs and creates outputs. Add Nuances to the Thought Network to create a decentralized computational fabric that securely processes data "everywhere". Using Nuances, we can automatically perform complex data analytics and artificial intelligence functions at the data level.  
Due to the structure and functionality of this Network, computational functions such as processing data models and performing machine learning algorithms become massively distributed; creating a significantly faster response time and improved performance. The structure enables instantaneous "action" based on computed results.
Smart Data and the Thought Network leverage Distributed Ledger Technologies (DLT) to create ecosystems of data models and AI algorithms. This marriage of Smart Data and DLT results in a dynamic, universal value-driven marketplace for a diversity of data and data insight.
The Thought utility token (THT) will be used to enable functionality on the Network, as well as, compensate algorithm developers, data scientists, and integrators for their data models and Network development work.

This Whitepaper introduces:

the Thought Network, 
specifications for the Nuance, it's connectivity to traditional systems and external data streams and computation capabilities (Oracles), 
specifications for the Active Data Transformation Fabric (ADTF) Node and it's connectivity to traditional systems and external data streams and computation capabilities,
autonomous Nuances, low level "tiny" agents (automata) that create useful and valuable emergent properties that reveal data insight and knowledge,
the Nuance Virtual Machine (NVM) architecture and structure,
a framework for a novel data model using consensus-driven templates for Smart Data instantiation using templates called "Concepts".
a novel class of proof-of-evolution DLT scheme which allows proof that a piece of data was processed in a meaningful/valuable way,
a standard framework for managing and assigning a real monetary or non-monetary value with a dynamic marketplace, to data, information, knowledge and insight.
Important implementation factors will be outlined, a) representative use cases, b) connections to traditional systems, and use of the protocol.

For feedback or comments, contact us at research@Thought.live. The Thought network is a work in progress. Research and Development is ongoing and constant, and new versions of this paper will appear at https://github.com/thoughtnetwork/thought-whitepaper



